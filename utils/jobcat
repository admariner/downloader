#!/usr/bin/env ruby
#
# Reads URLs from STDIN and submits them as download jobs to a downloader
#
# Usage:
#
#   $ jobcat [downloader-endpoint] [aggregation-limit]
#
# Example:
#
#   $ cat urls.txt | jobcat http://downloader.foo/download 5
#
require "json"
require "net/http"

DOWNLOADER = URI(ARGV[0])
AGGR_LIMIT = Integer(ARGV[1])

raise "Nothing passed to STDIN" if STDIN.tty?

i = 0
success = 0
error = 0

trap("SIGINT") {
  puts "Total requests: #{i} | Successful: #{success} | Error: #{error}"
  abort
}

Net::HTTP.start(DOWNLOADER.host, DOWNLOADER.port) do |http|
  STDIN.each do |line|
    line.chomp!
    i += 1

    begin
      download_uri = URI.parse(line)
    rescue => e
      puts e
      puts "Skipping malformed URL: #{line}"
      next
    end

    if !download_uri.absolute?
      puts "Skipping relative URL: #{line}"
      next
    end

    aggr_id = download_uri.host
    print "Enqueueing job ##{i} for #{aggr_id} ... "

    req = Net::HTTP::Post.new(DOWNLOADER, "Content-Type" => "application/json", "X-Aggr" => aggr_id)
    req.body = {
	    aggr_id: aggr_id, aggr_limit: AGGR_LIMIT,
      url: download_uri, callback_url: "http://localhost/callback",
      extra: Time.now.to_s
    }.to_json

    res = http.request(req)

    if res.code == "201"
      success += 1
      print "OK!\n"
    else
	    print "#{res.code}: #{res.body}\n"
      error += 1
    end
  end
end

puts "Total requests: #{i} | Successful: #{success} | Error: #{error}"
